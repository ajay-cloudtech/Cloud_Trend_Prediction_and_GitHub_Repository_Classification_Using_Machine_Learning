{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c948fded-5e3a-4079-895b-e4873dd51a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset size: 80525 rows\n",
      "\n",
      "Testing with 100 repositories:\n",
      "\n",
      "Testing with 1000 repositories:\n",
      "\n",
      "Testing with 10000 repositories:\n",
      "\n",
      "Testing with 25000 repositories:\n",
      "\n",
      "Testing with 50000 repositories:\n",
      "\n",
      "Testing with 80525 repositories:\n",
      "\n",
      "Performance Results:\n",
      "                          label  latency  throughput  dataset_size  hamming_score\n",
      "  XGBoost Inference (100 repos)     0.79      126.07           100           1.00\n",
      " XGBoost Inference (1000 repos)     1.26      796.42          1000           0.99\n",
      "XGBoost Inference (10000 repos)     4.58     2182.88         10000           0.99\n",
      "XGBoost Inference (25000 repos)     9.88     2531.51         25000           0.99\n",
      "XGBoost Inference (50000 repos)    19.65     2544.24         50000           0.99\n",
      "XGBoost Inference (80525 repos)    29.46     2733.61         80525           0.99\n",
      "\n",
      "Saved performance metrics to 'xgboost_performance_metrics.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset and models\n",
    "df = pd.read_csv(\"github_repos_filtered.csv\")\n",
    "xgb_model = joblib.load(\"xgboost_model.pkl\")\n",
    "language_encoder = joblib.load(\"language_encoder.pkl\")\n",
    "vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
    "full_size = len(df)\n",
    "print(f\"Full dataset size: {full_size} rows\")\n",
    "\n",
    "# Define inference function with performance metrics\n",
    "def measure_performance(df_subset, label):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Preprocess features\n",
    "    descriptions = df_subset['description'].fillna('')\n",
    "    description_tfidf = vectorizer.transform(descriptions)\n",
    "    features = pd.DataFrame(description_tfidf.toarray(), columns=[f'tfidf_{i}' for i in range(523)])\n",
    "    \n",
    "    languages = ['JavaScript', 'Python', 'TypeScript', 'Jupyter Notebook', 'Java', 'C#', 'Go', 'PHP', 'C++', 'Vue', 'Bicep', 'Kotlin', 'Dart', 'Rust', 'C', 'Ruby']\n",
    "    for lang in languages:\n",
    "        features[lang] = (df_subset['language'] == lang).astype(int)\n",
    "    \n",
    "    features['year'] = 2025\n",
    "    features['month'] = 3\n",
    "    features['day'] = 22\n",
    "    features['week'] = 12\n",
    "    features['size'] = df_subset['size']\n",
    "    features['is_cloud_project'] = df_subset['description'].str.lower().str.contains('cloud').fillna(False).astype(int)\n",
    "    features['language'] = df_subset['language'].apply(lambda x: language_encoder.transform([x])[0] if x in language_encoder.classes_ else -1)\n",
    "    \n",
    "    expected_columns = ['size', 'language'] + languages + ['year', 'month', 'day', 'week', 'is_cloud_project'] + [f'tfidf_{i}' for i in range(523)]\n",
    "    features = features[expected_columns]\n",
    "    \n",
    "    # Predict\n",
    "    predictions = xgb_model.predict(features)\n",
    "    if predictions.ndim == 2:\n",
    "        predictions = (predictions > 0.5).astype(int)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    latency = end_time - start_time\n",
    "    throughput = len(df_subset) / latency\n",
    "    dataset_size = len(df_subset)\n",
    "    \n",
    "    # Hamming Score (fraction of correct labels)\n",
    "    true_labels = df_subset[['AWS', 'Azure', 'GCP', 'Docker', 'Kubernetes', 'Terraform', 'DevOps']].values\n",
    "    hamming_score = accuracy_score(true_labels, predictions, normalize=True)\n",
    "    \n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"latency\": latency,\n",
    "        \"throughput\": throughput,\n",
    "        \"dataset_size\": dataset_size,\n",
    "        \"hamming_score\": hamming_score\n",
    "    }\n",
    "\n",
    "# Test different sizes\n",
    "sizes = [100, 1000, 10000, 25000, 50000, full_size]\n",
    "results = []\n",
    "\n",
    "for size in sizes:\n",
    "    print(f\"\\nTesting with {size} repositories:\")\n",
    "    if size <= full_size:\n",
    "        sampled_df = df.sample(n=size, random_state=42)\n",
    "    else:\n",
    "        repeat_factor = (size // full_size) + 1\n",
    "        sampled_df = pd.concat([df] * repeat_factor, ignore_index=True).iloc[:size]\n",
    "    \n",
    "    result = measure_performance(sampled_df, f\"XGBoost Inference ({size} repos)\")\n",
    "    if result:\n",
    "        results.append(result)\n",
    "\n",
    "# Output results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['latency'] = results_df['latency'].round(2)\n",
    "results_df['throughput'] = results_df['throughput'].round(2)\n",
    "results_df['hamming_score'] = results_df['hamming_score'].round(2)\n",
    "print(\"\\nPerformance Results:\")\n",
    "print(results_df.to_string(index=False))\n",
    "results_df.to_csv(\"xgboost_performance_metrics.csv\", index=False)\n",
    "print(\"\\nSaved performance metrics to 'xgboost_performance_metrics.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e2aac-2488-45df-80b8-34936e87ad71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
