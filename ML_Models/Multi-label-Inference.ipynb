{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5576322-0fe9-435d-b8ce-42c90859be81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted tags for repository 'terraform':\n",
      "- AWS\n",
      "- Azure\n",
      "- GCP\n",
      "- Terraform\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import base64\n",
    "from datetime import datetime\n",
    "import numpy as np  # Import NumPy\n",
    "\n",
    "# Load the saved model and encoders\n",
    "xgb_model = joblib.load(\"xgboost_model.pkl\")\n",
    "language_encoder = joblib.load(\"language_encoder.pkl\")\n",
    "vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
    "\n",
    "# GitHub repository details (owner and repo name)\n",
    "owner = \"e2eSolutionArchitect\"\n",
    "repo_name = \"terraform\"\n",
    "\n",
    "# GitHub API URL to fetch repository details\n",
    "repo_url = f\"https://api.github.com/repos/{owner}/{repo_name}\"\n",
    "\n",
    "# Fetch repository details using GitHub API\n",
    "repo_data = requests.get(repo_url).json()\n",
    "\n",
    "# Extract relevant details from the repo\n",
    "repo_title = repo_data['name']\n",
    "repo_description = repo_data['description'] if repo_data['description'] else ''\n",
    "repo_language = repo_data['language'] if repo_data['language'] else 'Unknown'\n",
    "repo_size = repo_data['size']  # Add size feature\n",
    "\n",
    "# Fetch content from the repository (e.g., README)\n",
    "readme_url = f\"https://api.github.com/repos/{owner}/{repo_name}/contents/README.md\"\n",
    "readme_data = requests.get(readme_url).json()\n",
    "if readme_data.get('content'):\n",
    "    content = base64.b64decode(readme_data['content']).decode('utf-8')\n",
    "else:\n",
    "    content = ''\n",
    "\n",
    "# Get the current date for the temporal features\n",
    "current_date = datetime.now()\n",
    "year = current_date.year\n",
    "month = current_date.month\n",
    "day = current_date.day\n",
    "week = current_date.isocalendar()[1]  # Week of the year\n",
    "\n",
    "# Process the description using the TF-IDF vectorizer\n",
    "description_tfidf = vectorizer.transform([repo_description])\n",
    "\n",
    "# Prepare the features\n",
    "features = pd.DataFrame(description_tfidf.toarray(), columns=[f'tfidf_{i}' for i in range(523)])\n",
    "\n",
    "# Ensure the language encoding\n",
    "if repo_language not in language_encoder.classes_:\n",
    "    print(f\"Warning: Unseen language '{repo_language}' encountered. Using default encoding.\")\n",
    "    repo_language_encoded = -1  # Placeholder for unseen language\n",
    "else:\n",
    "    repo_language_encoded = language_encoder.transform([repo_language])[0]\n",
    "\n",
    "# Add the language and temporal features\n",
    "languages = ['JavaScript', 'Python', 'TypeScript', 'Jupyter Notebook', 'Java', 'C#', 'Go', 'PHP', 'C++', 'Vue', 'Bicep', 'Kotlin', 'Dart', 'Rust', 'C', 'Ruby']\n",
    "for lang in languages:\n",
    "    features[lang] = 1 if lang == repo_language else 0\n",
    "\n",
    "# Add the temporal features (year, month, day, week)\n",
    "features['year'] = year\n",
    "features['month'] = month\n",
    "features['day'] = day\n",
    "features['week'] = week\n",
    "\n",
    "# Add other features\n",
    "features['size'] = repo_size\n",
    "features['is_cloud_project'] = 1 if 'cloud' in repo_description.lower() else 0\n",
    "\n",
    "# Add the language feature\n",
    "features['language'] = repo_language_encoded\n",
    "\n",
    "# Ensure the structure is the same as the training data\n",
    "# Reorder columns to match the training data\n",
    "expected_columns = ['size', 'language'] + languages + ['year', 'month', 'day', 'week', 'is_cloud_project'] + [f'tfidf_{i}' for i in range(523)]\n",
    "features = features[expected_columns]\n",
    "\n",
    "# Get predictions from the model\n",
    "try:\n",
    "    predictions = xgb_model.predict(features)\n",
    "    \n",
    "    # If the predictions are probabilities, apply a threshold of 0.5 to classify\n",
    "    if isinstance(predictions, np.ndarray) and predictions.ndim == 2:\n",
    "        predictions = (predictions > 0.5).astype(int)\n",
    "    \n",
    "    # Map predictions to appropriate tags\n",
    "    tags = ['AWS', 'Azure', 'GCP', 'Docker', 'Kubernetes', 'Terraform', 'DevOps']\n",
    "    predicted_tags = {tags[i]: predictions[0][i] for i in range(len(tags))}\n",
    "\n",
    "    # Output the predicted tags for the repository\n",
    "    print(f\"Predicted tags for repository '{repo_title}':\")\n",
    "    for tag, prediction in predicted_tags.items():\n",
    "        if prediction == 1:\n",
    "            print(f\"- {tag}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during prediction: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1020c61f-223b-4053-a0ae-cbb2acc961e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
