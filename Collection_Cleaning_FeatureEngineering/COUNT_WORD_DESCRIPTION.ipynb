{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a4c488f-fb5f-483a-a190-637d93425609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ajayp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Word  Count\n",
      "151          aws  19288\n",
      "35         cloud  19096\n",
      "42         azure  11720\n",
      "29         using   9166\n",
      "28       project   7583\n",
      "..           ...    ...\n",
      "705  engineering    779\n",
      "268          cdk    769\n",
      "93       example    766\n",
      "10      security    759\n",
      "90     framework    750\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"github_repos_filtered_language.csv\")\n",
    "\n",
    "# Drop rows where description is missing\n",
    "df = df.dropna(subset=[\"description\"])\n",
    "\n",
    "# Convert descriptions to lowercase and concatenate them into one large text\n",
    "text = \" \".join(df[\"description\"].astype(str).str.lower())\n",
    "\n",
    "# Define stopwords (common words to ignore)\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Tokenize text and remove special characters, numbers, and stopwords\n",
    "words = re.findall(r'\\b[a-zA-Z]{2,}\\b', text)  # Keep words with 2+ letters\n",
    "filtered_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "# Count word frequencies\n",
    "word_counts = Counter(filtered_words)\n",
    "\n",
    "# Convert to DataFrame for easy viewing\n",
    "word_freq_df = pd.DataFrame(word_counts.items(), columns=[\"Word\", \"Count\"])\n",
    "word_freq_df = word_freq_df.sort_values(by=\"Count\", ascending=False)\n",
    "\n",
    "# Display the top 20 most common words\n",
    "print(word_freq_df.head(100))\n",
    "\n",
    "# Save to CSV for further analysis\n",
    "word_freq_df.to_csv(\"word_frequencies.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd1aff6-e6ed-4e61-b912-8ee7d3199dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
